{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/devparikh0506/DATA_690_Deep_Learning/blob/main/week_4/FeedForwardNeuralNetwork.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## [source](https://github.com/bufuchangfeng/NeuralNetwork/blob/nn/nn_and_cnn.ipynb)"
      ],
      "metadata": {
        "id": "juX2QHAKBgaT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f2Np2dRGuFsb"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import shuffle\n",
        "import matplotlib.pyplot as plt\n",
        "from abc import ABC, abstractmethod\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "kvbqoIZ_z9Kz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52c701cb-627a-4fb5-a5ef-52721b8339bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(42)"
      ],
      "metadata": {
        "id": "r783zRf4MDSX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(path):\n",
        "    \"\"\"Loads the MNIST dataset and splits it into training and testing sets.\n",
        "\n",
        "    Args:\n",
        "        path (str): Path to the MNIST dataset file.\n",
        "\n",
        "    Returns:\n",
        "        Tuple: (x_train, y_train, x_test, y_test)\n",
        "    \"\"\"\n",
        "    with np.load(path) as f:\n",
        "        # Load training data and labels\n",
        "        x_train, y_train = f['x_train'], f['y_train']\n",
        "        # Load testing data and labels\n",
        "        x_test, y_test = f['x_test'], f['y_test']\n",
        "        return x_train, y_train, x_test, y_test\n",
        "\n",
        "# Load MNIST dataset\n",
        "train_data, train_label, test_data, test_label = load_data('/content/drive/MyDrive/DATA-690-deep-learning/data/mnist.npz')"
      ],
      "metadata": {
        "id": "s_O0MDfY_uPs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# normalize the image data\n",
        "X_train = (train_data/255 - 0.5)*2\n",
        "X_test = (test_data/255 - 0.5)*2"
      ],
      "metadata": {
        "id": "Q6nd-S_46_UI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AUWNTaQMA0M_",
        "outputId": "e3cc840f-b7bd-4a34-803b-a0921f75d6e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Reshape the training data to have a channel dimension\n",
        "train_data = X_train.reshape(-1, 1, 28, 28)"
      ],
      "metadata": {
        "id": "ar6C1Np5O92r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_label.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MkgkwUaUA437",
        "outputId": "7b07cfc2-92e2-4181-9e0d-a2ec83b2e336"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000,)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lZlgPEh5A7UD",
        "outputId": "2e0a2ce7-dc74-4517-e823-3d867e825f01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = X_test.reshape(-1, 1, 28, 28)"
      ],
      "metadata": {
        "id": "jJUwaL8QPHaJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data, valid_data, train_label, valid_label = train_test_split(train_data, train_label, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "syoW_JzqBLJI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iAteLkirBW5D",
        "outputId": "1a201115-2fb1-4549-af94-54848e5832fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(48000, 1, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JDt5c2ZjuFsd",
        "outputId": "766c4c0a-c1e3-46d0-b794-90a4bb760581",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "plt.imshow(valid_data[2].reshape(28, 28))\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "valid_label[2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Bkeka7RBuxv",
        "outputId": "d7ade2e5-8145-4bce-dc1e-fcd90e7dff29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BgxGVU90uFsd"
      },
      "outputs": [],
      "source": [
        "def label_to_one_hot(y, n_class):\n",
        "    \"\"\"Converts labels to one-hot encoding.\n",
        "\n",
        "    Args:\n",
        "        y (numpy.ndarray): Array of labels.\n",
        "        n_class (int): Number of classes.\n",
        "\n",
        "    Returns:\n",
        "        numpy.ndarray: One-hot encoded labels.\n",
        "    \"\"\"\n",
        "    one_hot = np.zeros((y.shape[0], n_class))\n",
        "    for i in range(len(y)):\n",
        "        one_hot[i][int(y[i])] = 1\n",
        "\n",
        "    return one_hot"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: provide a generator to provide data as batches to  model\n",
        "\n",
        "def data_generator(data, label, batch_size):\n",
        "  \"\"\"\n",
        "  Generates batches of data and labels.\n",
        "\n",
        "  Args:\n",
        "    data: The input data.\n",
        "    label: The corresponding labels.\n",
        "    batch_size: The size of each batch.\n",
        "\n",
        "  Yields:\n",
        "    A tuple of (data_batch, label_batch).\n",
        "  \"\"\"\n",
        "  num_samples = len(data)\n",
        "  num_batches = num_samples // batch_size\n",
        "\n",
        "  for i in range(num_batches):\n",
        "    start = i * batch_size\n",
        "    end = (i + 1) * batch_size\n",
        "    yield data[start:end], label[start:end]\n",
        "\n",
        "  # If there are remaining samples, yield a smaller batch.\n",
        "  if num_samples % batch_size != 0:\n",
        "    yield data[num_batches * batch_size:], label[num_batches * batch_size:]\n"
      ],
      "metadata": {
        "id": "U4YyVAdf4Acy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Layer(ABC):\n",
        "  \"\"\"The base class for NN model layer.\"\"\"\n",
        "  def __init__(self):\n",
        "      super.__init__()\n",
        "\n",
        "  @abstractmethod\n",
        "  def forward(self, x):\n",
        "    raise NotImplementedError\n",
        "\n",
        "  @abstractmethod\n",
        "  def backward(self, dout):\n",
        "    raise NotImplementedError"
      ],
      "metadata": {
        "id": "5zYeFs1duufR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Weight initialization function"
      ],
      "metadata": {
        "id": "uNgNIaCQ__Ug"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def he_uniform(weight_shape):\n",
        "    \"\"\"\n",
        "    Uniform(-b, b), b=sqrt(6/fan_in)\n",
        "    Args:\n",
        "        weight_shape: the shape of weight, for example (784, 300)\n",
        "    \"\"\"\n",
        "    fan_in, fan_out = weight_shape\n",
        "    b = np.sqrt(6 / fan_in)\n",
        "    return np.random.uniform(-b, b, size=weight_shape)"
      ],
      "metadata": {
        "id": "XXaj88zpABUh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iT4rJH-kuFsd"
      },
      "outputs": [],
      "source": [
        "class Linear(Layer):\n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        self.params = {}\n",
        "        self.params['W'] = he_uniform((input_dim, output_dim))\n",
        "        self.params['b'] = np.random.randn(output_dim)\n",
        "\n",
        "        self.grads = {}\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        self.x = x\n",
        "\n",
        "        out = np.dot(x, self.params['W']) + self.params['b']\n",
        "        return out\n",
        "\n",
        "    def backward(self, dout):\n",
        "\n",
        "        self.grads['W'] = np.dot(self.x.T, dout)\n",
        "        self.grads['b'] = np.sum(dout, axis=0)\n",
        "\n",
        "        return np.dot(dout, self.params['W'].T)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Adding Sigmoid Layer"
      ],
      "metadata": {
        "id": "vvpmUacp_KgS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Sigmoid(Layer):\n",
        "    def __init__(self):\n",
        "        self.params = None\n",
        "        self.out = None\n",
        "\n",
        "    def forward(self, x):\n",
        "        self.out = 1 / (1 + np.exp(-x))\n",
        "        return self.out\n",
        "\n",
        "    def backward(self, dout):\n",
        "        dx = dout * ( 1 - self.out) * self.out\n",
        "        return dx"
      ],
      "metadata": {
        "id": "VBKz_YQc-zML"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wB5jjKTWuFsd"
      },
      "outputs": [],
      "source": [
        "class ReLU(Layer):\n",
        "    def __init__(self):\n",
        "        self.params = None\n",
        "\n",
        "    def forward(self, x):\n",
        "        self.mask = (x <= 0)\n",
        "        out = x.copy()\n",
        "        out[self.mask] = 0\n",
        "\n",
        "        return out\n",
        "\n",
        "    def backward(self, dout):\n",
        "        dout[self.mask] = 0\n",
        "\n",
        "        return dout"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def softmax(x):\n",
        "    e_x = np.exp(x - np.max(x, axis=-1, keepdims=True))\n",
        "    return e_x / e_x.sum(axis=-1, keepdims=True)"
      ],
      "metadata": {
        "id": "07G9Qrb5GWNF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Os_NmQtTuFsd"
      },
      "outputs": [],
      "source": [
        "class SoftmaxWithCrossEntropyLoss(Layer):\n",
        "    def __init__(self):\n",
        "        self.params = None\n",
        "\n",
        "    def forward(self, out, y):\n",
        "        '''\n",
        "            out: output of last fully connected layer\n",
        "            y: true label\n",
        "        '''\n",
        "\n",
        "        batch_size = out.shape[0]\n",
        "\n",
        "        # max_val = np.max(out, axis=1).reshape(-1, 1)\n",
        "        # # print(out)\n",
        "        # # print(max_val)\n",
        "        # exp_out = np.exp(out - max_val)\n",
        "        # sum_exp_out = np.sum(exp_out, axis=1).reshape(-1, 1)\n",
        "        # out = exp_out / sum_exp_out\n",
        "\n",
        "        out = softmax(out)\n",
        "\n",
        "        self.out = out\n",
        "        self.y = y\n",
        "\n",
        "        log_out = np.log(out + 1e-7)\n",
        "\n",
        "        loss = np.sum(-log_out * y)\n",
        "\n",
        "        return loss / batch_size, out\n",
        "\n",
        "    def backward(self, dout):\n",
        "        return (self.out - self.y) / batch_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O9j1LznQuFse"
      },
      "outputs": [],
      "source": [
        "class FNN(Layer):\n",
        "    def __init__(self):\n",
        "        self.layers = []\n",
        "        self.layers.append(Linear(784, 512)) # Changed first layer\n",
        "        self.layers.append(Sigmoid()) # changed ReLU to Sigmoid\n",
        "        self.layers.append(Linear(512, 256)) # added new hidden layer\n",
        "        self.layers.append(Sigmoid()) # changed ReLU to Sigmoid\n",
        "        self.layers.append(Linear(256, 128)) # modified hidden layer\n",
        "        self.layers.append(Sigmoid()) # changed ReLU to Sigmoid\n",
        "        self.layers.append(Linear(128, 64))  # modified hidden layer\n",
        "        self.layers.append(Sigmoid()) # changed ReLU to Sigmoid\n",
        "        self.layers.append(Linear(64, 10))  # modified ouput layer\n",
        "        self.layers.append(SoftmaxWithCrossEntropyLoss())\n",
        "\n",
        "\n",
        "    def forward(self, x, y):\n",
        "        batch_size = x.shape[0]\n",
        "\n",
        "        y = label_to_one_hot(y, 10)\n",
        "\n",
        "        x = x.reshape(batch_size, 784)\n",
        "\n",
        "        for layer in self.layers[:-1]:\n",
        "            x = layer.forward(x)\n",
        "\n",
        "        return self.layers[-1].forward(x, y)\n",
        "\n",
        "\n",
        "    def backward(self):\n",
        "        dout = 1\n",
        "        for layer in self.layers[::-1]:\n",
        "            dout = layer.backward(dout)\n",
        "\n",
        "    def save(self, filepath):\n",
        "        \"\"\"\n",
        "        Saves the parameters of the model to a .npz file.\n",
        "        \"\"\"\n",
        "        params = {}\n",
        "        for i, layer in enumerate(self.layers):\n",
        "            if hasattr(layer, 'params') and layer.params is not None:\n",
        "                for j, param in enumerate(layer.params):\n",
        "                    params[f'layer_{i}_param_{j}'] = param\n",
        "\n",
        "        np.savez(filepath, **params)\n",
        "        print(f\"Model parameters saved to {filepath}\")\n",
        "\n",
        "    def load(self, filepath):\n",
        "        \"\"\"\n",
        "        Loads the parameters of the model from a npz file.\n",
        "        \"\"\"\n",
        "        if not os.path.exists(filepath):\n",
        "            raise FileNotFoundError(f\"No file found at {filepath}\")\n",
        "\n",
        "        params = np.load(filepath)\n",
        "        for i, layer in enumerate(self.layers):\n",
        "            if hasattr(layer, 'params') and layer.params is not None:\n",
        "                for j in range(len(layer.params)):\n",
        "                    param_name = f'layer_{i}_param_{j}'\n",
        "                    if param_name in params:\n",
        "                        layer.params[j] = params[param_name]\n",
        "                    else:\n",
        "                        print(f\"Warning: {param_name} not found in the loaded file\")\n",
        "\n",
        "        print(f\"Model parameters loaded from {filepath}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Optimizer(ABC):\n",
        "    \"\"\"The base class for optimizer.\"\"\"\n",
        "    def __init__(self, learning_rate, layers):\n",
        "        super().__init__()\n",
        "\n",
        "    @abstractmethod\n",
        "    def update(self):\n",
        "        raise NotImplementedError"
      ],
      "metadata": {
        "id": "4MHzbP9bQM-a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SGD(Optimizer):\n",
        "    \"\"\"SGD (Stochastic gradient descent) optimizer\"\"\"\n",
        "    def __init__(self, learning_rate, layers):\n",
        "        self.learning_rate = learning_rate\n",
        "        self.layers = layers\n",
        "\n",
        "    def update(self):\n",
        "        for i in range(len(self.layers)):\n",
        "          layer = self.layers[i]\n",
        "          if layer.params is not None:\n",
        "            for key in layer.params.keys():\n",
        "              layer.params[key] -= self.learning_rate * layer.grads[key]"
      ],
      "metadata": {
        "id": "AKcD3el7HsB4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_and_valid(model, optimizer, train_data, train_label, valid_data, valid_label, epochs, batch_size):\n",
        "  \"\"\"\n",
        "  Trains and validates a neural network model.\n",
        "\n",
        "  Args:\n",
        "    model: The neural network model.\n",
        "    optimizer: The optimizer used for training.\n",
        "    train_data: The training data.\n",
        "    train_label: The training labels.\n",
        "    valid_data: The validation data.\n",
        "    valid_label: The validation labels.\n",
        "    epochs: The number of training epochs.\n",
        "    batch_size: The batch size for training.\n",
        "  \"\"\"\n",
        "  for epoch in range(epochs):\n",
        "    # Shuffle training data for each epoch\n",
        "    train_data, train_label = shuffle(train_data, train_label)\n",
        "\n",
        "    # Training loop\n",
        "    train_loss = 0\n",
        "    train_correct = 0\n",
        "    for data_batch, label_batch in data_generator(train_data, train_label, batch_size):\n",
        "      loss, output = model.forward(data_batch, label_batch)\n",
        "      train_loss += loss\n",
        "      train_correct += np.sum(np.argmax(output, axis=1) == label_batch)\n",
        "      model.backward()\n",
        "      optimizer.update()\n",
        "\n",
        "    # Validation loop\n",
        "    valid_loss = 0\n",
        "    valid_correct = 0\n",
        "    for data_batch, label_batch in data_generator(valid_data, valid_label, batch_size):\n",
        "      loss, output = model.forward(data_batch, label_batch)\n",
        "      valid_loss += loss\n",
        "      valid_correct += np.sum(np.argmax(output, axis=1) == label_batch)\n",
        "\n",
        "    print(f'Epoch: {epoch + 1}/{epochs}, Train Loss: {train_loss / len(train_data):.4f}, Train Acc: {train_correct / len(train_data):.4f}, Valid Loss: {valid_loss / len(valid_data):.4f}, Valid Acc: {valid_correct / len(valid_data):.4f}')"
      ],
      "metadata": {
        "id": "Zd_1_m2f6GJq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(model, test_data, test_label, batch_size=1):\n",
        "  \"\"\"\n",
        "  Tests the neural network model on the test dataset.\n",
        "\n",
        "  Args:\n",
        "    model: The neural network model.\n",
        "    test_data: The test data.\n",
        "    test_label: The test labels.\n",
        "    batch_size: The batch size for testing.\n",
        "  \"\"\"\n",
        "  test_correct = 0\n",
        "  for data_batch, label_batch in data_generator(test_data, test_label, batch_size):\n",
        "    _, output = model.forward(data_batch, label_batch)\n",
        "    test_correct += np.sum(np.argmax(output, axis=1) == label_batch)\n",
        "\n",
        "  print(f'Test Acc: {test_correct / len(test_data):.4f}')\n"
      ],
      "metadata": {
        "id": "ybOGOvPc8Ba7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_fnn = FNN()\n",
        "learning_rate = 5e-3\n",
        "epochs = 10\n",
        "batch_size = 256\n",
        "optimizer = SGD(learning_rate, model_fnn.layers)\n",
        "\n",
        "train_and_valid(model_fnn, optimizer, train_data, train_label, valid_data, valid_label, epochs, batch_size)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HclAqk256-RT",
        "outputId": "828d7658-3426-4f11-a6b4-24c9e1c94a75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1/10, Train Loss: 0.0096, Train Acc: 0.1075, Valid Loss: 0.0091, Valid Acc: 0.1102\n",
            "Epoch: 2/10, Train Loss: 0.0090, Train Acc: 0.1129, Valid Loss: 0.0090, Valid Acc: 0.1102\n",
            "Epoch: 3/10, Train Loss: 0.0090, Train Acc: 0.1129, Valid Loss: 0.0090, Valid Acc: 0.1102\n",
            "Epoch: 4/10, Train Loss: 0.0090, Train Acc: 0.1129, Valid Loss: 0.0090, Valid Acc: 0.1102\n",
            "Epoch: 5/10, Train Loss: 0.0090, Train Acc: 0.1129, Valid Loss: 0.0090, Valid Acc: 0.1102\n",
            "Epoch: 6/10, Train Loss: 0.0090, Train Acc: 0.1129, Valid Loss: 0.0090, Valid Acc: 0.1102\n",
            "Epoch: 7/10, Train Loss: 0.0090, Train Acc: 0.1129, Valid Loss: 0.0090, Valid Acc: 0.1102\n",
            "Epoch: 8/10, Train Loss: 0.0090, Train Acc: 0.1129, Valid Loss: 0.0090, Valid Acc: 0.1102\n",
            "Epoch: 9/10, Train Loss: 0.0090, Train Acc: 0.1129, Valid Loss: 0.0090, Valid Acc: 0.1102\n",
            "Epoch: 10/10, Train Loss: 0.0090, Train Acc: 0.1129, Valid Loss: 0.0090, Valid Acc: 0.1102\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Saving the model\n",
        "\n",
        "file = 'model_fnn.npz'\n",
        "model_fnn.save(file)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4MskyEoGElA_",
        "outputId": "d25da75e-bb02-4ed9-8f51-21aa3050a51e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model parameters saved to model_fnn.npz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading model\n",
        "file = 'model_fnn.npz'\n",
        "loaded_model = FNN()\n",
        "loaded_model.load(file)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SwsCv52XFe4Y",
        "outputId": "08cbe895-499f-4acc-ca02-94ce06ed9f97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model parameters loaded from model_fnn.npz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test(model_fnn, test_data, test_label)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RcrHoGmk78OL",
        "outputId": "2b20bafb-5fa0-492d-c56f-c435c4a3dfc1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Acc: 0.1135\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test(loaded_model, test_data, test_label)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "29XRZ6oICL9L",
        "outputId": "1e1327ed-9cae-4276-fda1-296698395747"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Acc: 0.0974\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}